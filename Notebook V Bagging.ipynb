{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "\n",
    "In this notebook I will cover bootstrap aggregating, or bagging. I will use the breast cancer dataset from Article II & III to test the performance of our ensemble algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a class to contain our ensemble. I'm going to make use of the make_bootstraps function I built in Article IV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make an ensemble classifier based on decision trees ##\n",
    "class BaggedTreeClassifier(object):\n",
    "    #initializer\n",
    "    def __init__(self,n_elements=100):\n",
    "        self.n_elements = n_elements\n",
    "        self.models     = []\n",
    "    \n",
    "    #destructor\n",
    "    def __del__(self):\n",
    "        del self.n_elements\n",
    "        del self.models\n",
    "        \n",
    "    #private function to make bootstrap samples\n",
    "    def __make_bootstraps(self,data):\n",
    "        #initialize output dictionary & unique value count\n",
    "        dc   = {}\n",
    "        unip = 0\n",
    "        #get sample size\n",
    "        b_size = data.shape[0]\n",
    "        #get list of row indexes\n",
    "        idx = [i for i in range(b_size)]\n",
    "        #loop through the required number of bootstraps\n",
    "        for b in range(self.n_elements):\n",
    "            #obtain boostrap samples with replacement\n",
    "            sidx   = np.random.choice(idx,replace=True,size=b_size)\n",
    "            b_samp = data[sidx,:]\n",
    "            #compute number of unique values contained in the bootstrap sample\n",
    "            unip  += len(set(sidx))\n",
    "            #obtain out-of-bag samples for the current b\n",
    "            oidx   = list(set(idx) - set(sidx))\n",
    "            o_samp = np.array([])\n",
    "            if oidx:\n",
    "                o_samp = data[oidx,:]\n",
    "            #store results\n",
    "            dc['boot_'+str(b)] = {'boot':b_samp,'test':o_samp}\n",
    "        #return the bootstrap results\n",
    "        return(dc)\n",
    "  \n",
    "    #public function to return model parameters\n",
    "    def get_params(self, deep = False):\n",
    "        return {'n_elements':self.n_elements}\n",
    "\n",
    "    #train the ensemble\n",
    "    def fit(self,X_train,y_train,print_metrics=False):\n",
    "        #package the input data\n",
    "        training_data = np.concatenate((X_train,y_train.reshape(-1,1)),axis=1)\n",
    "        #make bootstrap samples\n",
    "        dcBoot = self.__make_bootstraps(training_data)\n",
    "        #initialise metric arrays\n",
    "        accs = np.array([])\n",
    "        pres = np.array([])\n",
    "        recs = np.array([])\n",
    "        #iterate through each bootstrap sample & fit a model ##\n",
    "        cls = DecisionTreeClassifier(class_weight='balanced')\n",
    "        for b in dcBoot:\n",
    "            #make a clone of the model\n",
    "            model = clone(cls)\n",
    "            #fit a decision tree classifier to the current sample\n",
    "            model.fit(dcBoot[b]['boot'][:,:-1],dcBoot[b]['boot'][:,-1].reshape(-1, 1))\n",
    "            #append the fitted model\n",
    "            self.models.append(model)\n",
    "            #compute the predictions on the out-of-bag test set & compute metrics\n",
    "            if dcBoot[b]['test'].size:\n",
    "                yp  = model.predict(dcBoot[b]['test'][:,:-1])\n",
    "                acc = accuracy_score(dcBoot[b]['test'][:,-1],yp)\n",
    "                pre = precision_score(dcBoot[b]['test'][:,-1],yp)   \n",
    "                rec = recall_score(dcBoot[b]['test'][:,-1],yp)\n",
    "                #store the error metrics\n",
    "                accs = np.concatenate((accs,acc.flatten()))\n",
    "                pres = np.concatenate((pres,pre.flatten()))\n",
    "                recs = np.concatenate((recs,rec.flatten()))\n",
    "        #compute standard errors for error metrics\n",
    "        if print_metrics:\n",
    "            print(\"Standard error in accuracy: %.2f\" % np.std(accs))\n",
    "            print(\"Standard error in precision: %.2f\" % np.std(pres))\n",
    "            print(\"Standard error in recall: %.2f\" % np.std(recs))\n",
    "            \n",
    "    #predict from the ensemble\n",
    "    def predict(self,X):\n",
    "        #check we've fit the ensemble\n",
    "        if not self.models:\n",
    "            print('You must train the ensemble before making predictions!')\n",
    "            return(None)\n",
    "        #loop through each fitted model\n",
    "        predictions = []\n",
    "        for m in self.models:\n",
    "            #make predictions on the input X\n",
    "            yp = m.predict(X)\n",
    "            #append predictions to storage list\n",
    "            predictions.append(yp.reshape(-1,1))\n",
    "        #compute the ensemble prediction\n",
    "        ypred = np.round(np.mean(np.concatenate(predictions,axis=1),axis=1)).astype(int)\n",
    "        #return the prediction\n",
    "        return(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Here I'll load the breast cancer dataset. Note I already analysed these data in Article II & III. The classes are unbalanced so I will have to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load classification dataset ##\n",
    "data = load_breast_cancer()\n",
    "X    = data.data\n",
    "y    = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Ensemble & Produce Predictions\n",
    "\n",
    "Let's take our data and train an ensemble classifier based on decision trees. Use 10-fold cross-validation to check performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare an ensemble instance with default parameters ##\n",
    "ens = BaggedTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error in accuracy: 0.02\n",
      "Standard error in precision: 0.02\n",
      "Standard error in recall: 0.02\n"
     ]
    }
   ],
   "source": [
    "## train the ensemble & view estimates for prediction error ##\n",
    "ens.fit(X,y,print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.96\n",
      "Mean Precision: 0.97\n",
      "Mean Recall: 0.98\n"
     ]
    }
   ],
   "source": [
    "## use k fold cross validation to measure performance ##\n",
    "scoring_metrics = ['accuracy','precision','recall']\n",
    "dcScores        = cross_validate(ens,X,y,cv=StratifiedKFold(10),scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dcScores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dcScores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dcScores['test_recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look good, they represent an improvement, in terms of accuracy and recall, over the lone decision tree classifier (see results from Article III). Note that no hyperparameter tuning was done: further improvements to our ensemble are therefore possible.\n",
    "\n",
    "Let's compare how our custom-built ensemble compares to the one available through scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the scikit-learn model ##\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare a bagging classifier instance ##\n",
    "ens = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced'),n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.97\n",
      "Mean Precision: 0.97\n",
      "Mean Recall: 0.98\n"
     ]
    }
   ],
   "source": [
    "## use k fold cross validation to measure performance ##\n",
    "scoring_metrics = ['accuracy','precision','recall']\n",
    "dcScores        = cross_validate(ens,X,y,cv=StratifiedKFold(10),scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dcScores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dcScores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dcScores['test_recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results here are very similar to those obtained with our custom ensemble classifier. Like the case with the custom classifier, no hyperparameter tuning was done here. Further work to optimise the hyperparameters of the base decision tree classifier could offer further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
