{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "In this notebook I will implement decision tree models for both classification and regression.  I will use the breast cancer dataset from Article II to test the classification model, while the regression model will be tested using synthetic data.  Both implemented models will be compared to the decision trees available through scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "from abc import ABC,abstractmethod\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer,make_regression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,mean_squared_error,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to control tree node\n",
    "class Node:\n",
    "    #initializer\n",
    "    def __init__(self):\n",
    "        self.__Bs    = None\n",
    "        self.__Bf    = None\n",
    "        self.__left  = None\n",
    "        self.__right = None\n",
    "        self.leafv   = None\n",
    "\n",
    "    #set the split,feature parameters for this node\n",
    "    def set_params(self,Bs,Bf):\n",
    "        self.__Bs = Bs\n",
    "        self.__Bf = Bf\n",
    "        \n",
    "    #get the split,feature parameters for this node\n",
    "    def get_params(self):\n",
    "        return(self.__Bs,self.__Bf)    \n",
    "        \n",
    "    #set the left/right children nodes for this current node\n",
    "    def set_children(self,left,right):\n",
    "        self.__left  = left\n",
    "        self.__right = right\n",
    "        \n",
    "    #get the left child node\n",
    "    def get_left_node(self):\n",
    "        return(self.__left)\n",
    "    \n",
    "    #get the right child node\n",
    "    def get_right_node(self):\n",
    "        return(self.__right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base class to encompass the decision tree algorithm\n",
    "class DecisionTree(ABC):\n",
    "    #initializer\n",
    "    def __init__(self,max_depth=None,min_samples_split=2):\n",
    "        self.tree              = None\n",
    "        self.max_depth         = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "    #protected function to define the impurity\n",
    "    @abstractmethod\n",
    "    def _impurity(self,D):\n",
    "         pass\n",
    "        \n",
    "    #protected function to compute the value at a leaf node\n",
    "    @abstractmethod\n",
    "    def _leaf_value(self,D):\n",
    "         pass\n",
    "        \n",
    "    #private recursive function to grow the tree during training\n",
    "    def __grow(self,node,D,level):       \n",
    "        #are we in a leaf node? let's do some check...\n",
    "        depth = (self.max_depth is None) or (self.max_depth >= (level+1))\n",
    "        msamp = (self.min_samples_split <= D.shape[0])\n",
    "        n_cls = np.unique(D[:,-1]).shape[0] != 1\n",
    "        \n",
    "        #not a leaf node\n",
    "        if depth and msamp and n_cls:\n",
    "        \n",
    "            #initialize the function parameters\n",
    "            ip_node = None\n",
    "            feature = None\n",
    "            split   = None\n",
    "            left_D  = None\n",
    "            right_D = None\n",
    "            #iterrate through the possible feature/split combinations\n",
    "            for f in range(D.shape[1]-1):\n",
    "                for s in np.unique(D[:,f]):\n",
    "                    #for the current (f,s) combination, split the dataset\n",
    "                    D_l = D[D[:,f]<=s]\n",
    "                    D_r = D[D[:,f]>s]\n",
    "                    #ensure we have non-empty arrays\n",
    "                    if D_l.size and D_r.size:\n",
    "                        #calculate the impurity\n",
    "                        ip  = (D_l.shape[0]/D.shape[0])*self._impurity(D_l) + (D_r.shape[0]/D.shape[0])*self._impurity(D_r)\n",
    "                        #now update the impurity and choice of (f,s)\n",
    "                        if (ip_node is None) or (ip < ip_node):\n",
    "                            ip_node = ip\n",
    "                            feature = f\n",
    "                            split   = s\n",
    "                            left_D  = D_l\n",
    "                            right_D = D_r\n",
    "            #set the current node's parameters\n",
    "            node.set_params(split,feature)\n",
    "            #declare child nodes\n",
    "            left_node  = Node()\n",
    "            right_node = Node()\n",
    "            node.set_children(left_node,right_node)\n",
    "            #investigate child nodes\n",
    "            self.__grow(node.get_left_node(),left_D,level+1)\n",
    "            self.__grow(node.get_right_node(),right_D,level+1)\n",
    "                        \n",
    "        #is a leaf node\n",
    "        else:\n",
    "            \n",
    "            #set the node value & return\n",
    "            node.leafv = self._leaf_value(D)\n",
    "            return\n",
    "     \n",
    "    #private recursive function to traverse the (trained) tree\n",
    "    def __traverse(self,node,Xrow):\n",
    "        #check if we're in a leaf node?\n",
    "        if node.leafv is None:\n",
    "            #get parameters at the node\n",
    "            (s,f) = node.get_params()\n",
    "            #decide to go left or right?\n",
    "            if (Xrow[f] <= s):\n",
    "                return(self.__traverse(node.get_left_node(),Xrow))\n",
    "            else:\n",
    "                return(self.__traverse(node.get_right_node(),Xrow))\n",
    "        else:\n",
    "            #return the leaf value\n",
    "            return(node.leafv)\n",
    "    \n",
    "    #train the tree model\n",
    "    def train(self,Xin,Yin):\n",
    "        #prepare the input data\n",
    "        D = np.concatenate((Xin,Yin.reshape(-1,1)),axis=1)\n",
    "        #set the root node of the tree\n",
    "        self.tree = Node()\n",
    "        #build the tree\n",
    "        self.__grow(self.tree,D,1)\n",
    "        \n",
    "    #make predictions from the trained tree\n",
    "    def predict(self,Xin):\n",
    "        #iterrate through the rows of Xin\n",
    "        p = []\n",
    "        for r in range(Xin.shape[0]):\n",
    "            p.append(self.__traverse(self.tree,Xin[r,:]))\n",
    "        #return predictions\n",
    "        return(np.array(p).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "class DecisionTreeClassifier(DecisionTree):\n",
    "    #initializer\n",
    "    def __init__(self,max_depth=None,min_samples_split=2,loss='gini'):\n",
    "        DecisionTree.__init__(self,max_depth,min_samples_split)\n",
    "        self.loss = loss   \n",
    "    \n",
    "    #private function to define the gini impurity\n",
    "    def __gini(self,D):\n",
    "        #initialize the output\n",
    "        G = 0\n",
    "        #iterrate through the unique classes\n",
    "        for c in np.unique(D[:,-1]):\n",
    "            #compute p for the current c\n",
    "            p = D[D[:,-1]==c].shape[0]/D.shape[0]\n",
    "            #compute term for the current c\n",
    "            G += p*(1-p)\n",
    "        #return gini impurity\n",
    "        return(G)\n",
    "    \n",
    "    #private function to define the shannon entropy\n",
    "    def __entropy(self,D):\n",
    "        #initialize the output\n",
    "        H = 0\n",
    "        #iterrate through the unique classes\n",
    "        for c in np.unique(D[:,-1]):\n",
    "            #compute p for the current c\n",
    "            p = D[D[:,-1]==c].shape[0]/D.shape[0]\n",
    "            #compute term for the current c\n",
    "            H -= p*np.log2(p)\n",
    "        #return entropy\n",
    "        return(H)\n",
    "    \n",
    "    #protected function to define the impurity\n",
    "    def _impurity(self,D):\n",
    "        #use the selected loss function to calculate the node impurity\n",
    "        ip = None\n",
    "        if self.loss == 'gini':\n",
    "            ip = self.__gini(D)\n",
    "        elif self.loss == 'entropy':\n",
    "            ip = self.__entropy(D)\n",
    "        #return results\n",
    "        return(ip)\n",
    "    \n",
    "    #protected function to compute the value at a leaf node\n",
    "    def _leaf_value(self,D):\n",
    "         return(stats.mode(D[:,-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "class DecisionTreeRegressor(DecisionTree):\n",
    "    #initializer\n",
    "    def __init__(self,max_depth=None,min_samples_split=2,loss='mse'):\n",
    "        DecisionTree.__init__(self,max_depth,min_samples_split)\n",
    "        self.loss = loss   \n",
    "    \n",
    "    #private function to define the mean squared error\n",
    "    def __mse(self,D):\n",
    "        #compute the mean target for the node\n",
    "        y_m = np.mean(D[:,-1])\n",
    "        #compute the mean squared error wrt the mean\n",
    "        E = np.sum((D[:,-1] - y_m)**2)/D.shape[0]\n",
    "        #return mse\n",
    "        return(E)\n",
    "    \n",
    "    #private function to define the mean absolute error\n",
    "    def __mae(self,D):\n",
    "        #compute the mean target for the node\n",
    "        y_m = np.mean(D[:,-1])\n",
    "        #compute the mean absolute error wrt the mean\n",
    "        E = np.sum(np.abs(D[:,-1] - y_m))/D.shape[0]\n",
    "        #return mae\n",
    "        return(E)\n",
    "    \n",
    "    #protected function to define the impurity\n",
    "    def _impurity(self,D):\n",
    "        #use the selected loss function to calculate the node impurity\n",
    "        ip = None\n",
    "        if self.loss == 'mse':\n",
    "            ip = self.__mse(D)\n",
    "        elif self.loss == 'mae':\n",
    "            ip = self.__mae(D)\n",
    "        #return results\n",
    "        return(ip)\n",
    "    \n",
    "    #protected function to compute the value at a leaf node\n",
    "    def _leaf_value(self,D):\n",
    "         return(np.mean(D[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model\n",
    "\n",
    "Let's test out the classification model, using the breast cancer dataset we already examined in Article II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load classification dataset ##\n",
    "data = load_breast_cancer()\n",
    "X    = data.data\n",
    "y    = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (569, 30)\n",
      "shape of y:  (569,)\n"
     ]
    }
   ],
   "source": [
    "## what is the shape of the dataset? ##\n",
    "print('shape of X: ',X.shape)\n",
    "print('shape of y: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of y=0:  0.37258347978910367\n",
      "Percentage of y=1:  0.6274165202108963\n"
     ]
    }
   ],
   "source": [
    "## is the dataset balanced? ##\n",
    "plt.hist(y)\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('counts')\n",
    "plt.show()\n",
    "\n",
    "print('Percentage of y=0: ',y[y==0].shape[0]/y.shape[0])\n",
    "print('Percentage of y=1: ',y[y==1].shape[0]/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this dataset isn't balanced. We will need to account for this prior to training. I'll do this by selecting samples for training based upon their class values, ensuring I get an equal number for each class.  I want to use 60% of the data for training, and test the results on the remaining 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how many samples do I need per class for training? ##\n",
    "nsampclass = int(np.round(y.shape[0]*0.6/2,decimals=0))\n",
    "nsampclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do train/test split ##\n",
    "#partition the training data by label\n",
    "y0 = y[y==0]\n",
    "y1 = y[y==1]\n",
    "X0 = X[y==0]\n",
    "X1 = X[y==1]\n",
    "#select the elements to remove at random\n",
    "idx0 = np.random.choice([i for i in range(y0.shape[0])],size=nsampclass,replace=False)\n",
    "idx1 = np.random.choice([i for i in range(y1.shape[0])],size=nsampclass,replace=False)\n",
    "#select samples for training\n",
    "y_train0 = y0[idx0]\n",
    "y_train1 = y1[idx1]\n",
    "X_train0 = X0[idx0,:]\n",
    "X_train1 = X1[idx1,:]\n",
    "y_train  = np.concatenate((y_train0,y_train1))\n",
    "X_train  = np.concatenate((X_train0,X_train1))\n",
    "#use remainder for testing\n",
    "y_test0 = np.delete(y0,idx0)\n",
    "y_test1 = np.delete(y1,idx1)\n",
    "X_test0 = np.delete(X0,idx0,axis=0)\n",
    "X_test1 = np.delete(X1,idx1,axis=0)\n",
    "y_test  = np.concatenate((y_test0,y_test1))\n",
    "X_test  = np.concatenate((X_test0,X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUKUlEQVR4nO3df7BndX3f8eeLXcEYoSzuXYq7xAVnNQGL1Vwp1SZjoAYkKUsdySwNcUeZbG2JMZmmEUwitunOYH60MSQk2VFgTS0MA0RI26h0UyWtAl6UXwshbMXAyspeJMZEHXTh3T++Zz9+Xe6yX+7e7/e7936fj5k73+/5nPM95/2Ze+e87jnnez4nVYUkSQCHjbsASdKhw1CQJDWGgiSpMRQkSY2hIElqlo+7gIOxcuXKWrt27bjLkKRF5c4773yiqqbmmreoQ2Ht2rXMzMyMuwxJWlSS/PX+5nn6SJLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQs6juaD9bai//HWLb7pct+YizblbSwxrUPgeHtRzxSkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDVDC4UkVybZneS+fdrfleTBJNuT/EZf+yVJdnTzzhxWXZKk/RvmMBdXA78HfGRvQ5IfA9YDp1TVU0lWde0nARuAk4GXAv8rySuq6ukh1idJ2sfQjhSq6lbgyX2a/w1wWVU91S2zu2tfD1xbVU9V1cPADuDUYdUmSZrbqK8pvAL4kSS3J/l0ktd17auBR/uW29m1PUuSTUlmkszMzs4OuVxJmiyjDoXlwArgNODfA9clCZA5lq25VlBVW6pquqqmp6amhlepJE2gUYfCTuDG6rkDeAZY2bUf37fcGuCxEdcmSRNv1KHwMeB0gCSvAA4HngBuBjYkOSLJCcA64I4R1yZJE29o3z5Kcg3wRmBlkp3ApcCVwJXd11S/DWysqgK2J7kOuB/YA1zkN48kafSGFgpVdf5+Zl2wn+U3A5uHVY8k6cC8o1mS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVIztFBIcmWS3d0Ddfad90tJKsnKvrZLkuxI8mCSM4dVlyRp/4Z5pHA1cNa+jUmOB94EPNLXdhKwATi5+8wVSZYNsTZJ0hyGFgpVdSvw5Byz/gvwy0D1ta0Hrq2qp6rqYWAHcOqwapMkzW2k1xSSnAN8uaru3mfWauDRvumdXdtc69iUZCbJzOzs7JAqlaTJNLJQSPIi4FeA9801e462mqONqtpSVdNVNT01NbWQJUrSxFs+wm29HDgBuDsJwBrg80lOpXdkcHzfsmuAx0ZYmySJER4pVNW9VbWqqtZW1Vp6QfDaqvoKcDOwIckRSU4A1gF3jKo2SVLPML+Seg3wWeCVSXYmuXB/y1bVduA64H7g48BFVfX0sGqTJM1taKePqur8A8xfu8/0ZmDzsOqRJB2YdzRLkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqhvmQnSuT7E5yX1/bbyb5yyT3JPmTJEf3zbskyY4kDyY5c1h1SZL2b5hHClcDZ+3Tdgvwqqo6Bfgr4BKAJCcBG4CTu89ckWTZEGuTJM1haKFQVbcCT+7T9smq2tNN3gas6d6vB66tqqeq6mFgB3DqsGqTJM1tnNcU3gH8Wfd+NfBo37ydXduzJNmUZCbJzOzs7JBLlKTJMpZQSPIrwB7go3ub5lis5vpsVW2pqumqmp6amhpWiZI0kZaPeoNJNgI/CZxRVXt3/DuB4/sWWwM8NuraJGnSjfRIIclZwHuAc6rqm32zbgY2JDkiyQnAOuCOUdYmSRrikUKSa4A3AiuT7AQupfdtoyOAW5IA3FZV76yq7UmuA+6nd1rpoqp6eli1SZLmNrRQqKrz52j+8HMsvxnYPKx6JEkH5h3NkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQMLRSSXJlkd5L7+tqOSXJLkoe61xV98y5JsiPJg0nOHFZdkqT9G+aRwtXAWfu0XQxsq6p1wLZumiQnARuAk7vPXJFk2RBrkyTNYaBQSPLuJEel58NJPp/kx5/rM1V1K/DkPs3rga3d+63AuX3t11bVU1X1MLADOHXQTkiSFsagRwrvqKqvAz8OTAFvBy6bx/aOrapdAN3rqq59NfBo33I7u7ZnSbIpyUySmdnZ2XmUIEnan0FDId3r2cBVVXV3X9tCmGtdNdeCVbWlqqaranpqamoBS5AkDRoKdyb5JL1Q+ESSI4Fn5rG9x5McB9C97u7adwLH9y23BnhsHuuXJB2EQUPhQnoXhV9XVd8EDqd3Cun5uhnY2L3fCNzU174hyRFJTgDWAXfMY/2SpIOwfMDlbqmqM/ZOVNVXk1wHnLG/DyS5BngjsDLJTuBSetchrktyIfAIcF63vu3d+u4H9gAXVdXT8+iPJOkgPGcoJHkh8CJ6O/YVfPfc/1HAS5/rs1V1/n5mzRkkVbUZ2Pyc1UqShupARwr/GvgFegFwJ98Nha8Dvz+8siRJ4/CcoVBVHwQ+mORdVXX5iGqSJI3JQNcUquryJK8H1vZ/pqo+MqS6JEljMFAoJPlj4OXAXcDeC8AFGAqStIQM+u2jaeCkqprzhjJJ0tIw6H0K9wH/cJiFSJLGb9AjhZXA/UnuAJ7a21hV5wylKknSWAwaCu8fZhGSpEPDoN8++vSwC5Ekjd+g3z76O747aunhwAuAb1TVUcMqTJI0eoMeKRzZP53kXHwIjiQtOfN6HGdVfQw4fWFLkSSN26Cnj97SN3kYvfsWvGdBkpaYQb999C/63u8BvkTvucqSpCVk0GsK83mgjiRpkRnomkKSNUn+JMnuJI8nuSHJmvluNMkvJtme5L4k1yR5YZJjktyS5KHudcV81y9Jmp9BLzRfRe+RmS8FVgN/2rU9b0lWAz8PTFfVq4BlwAZ6j/vcVlXrgG3dtCRphAYNhamquqqq9nQ/VwNTB7Hd5cD3JVlO78luj9G7RrG1m78VOPcg1i9JmodBQ+GJJBckWdb9XAB8dT4brKovA79F7xnNu4C/rapPAsdW1a5umV3Aqrk+n2RTkpkkM7Ozs/MpQZK0H4OGwjuAnwK+Qm9H/lZgXhefu2sF64ET6J2O+v4uZAZSVVuqarqqpqemDuZgRZK0r0FD4deBjVU1VVWr6IXE++e5zX8OPFxVs1X1HeBG4PXA40mOA+hed89z/ZKkeRo0FE6pqr/ZO1FVTwKvmec2HwFOS/KiJAHOAB6gdyF7Y7fMRuCmea5fkjRPg968dliSFXuDIckxz+Oz36Oqbk9yPfB5ejfCfQHYArwYuC7JhfSC47z5rF+SNH+D7th/G/hMtzMvetcXNs93o1V1KXDpPs1P0TtqkCSNyaB3NH8kyQy9QfACvKWq7h9qZZKkkRv4FFAXAgaBJC1h8xo6W5K0NBkKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEnNWEIhydFJrk/yl0keSPJPkxyT5JYkD3WvK8ZRmyRNsnEdKXwQ+HhV/SDwanqP47wY2FZV64Bt3bQkaYRGHgpJjgJ+FPgwQFV9u6q+BqwHtnaLbQXOHXVtkjTpxnGkcCIwC1yV5AtJPpTk+4Fjq2oXQPe6aq4PJ9mUZCbJzOzs7OiqlqQJMI5QWA68FviDqnoN8A2ex6miqtpSVdNVNT01NTWsGiVpIo0jFHYCO6vq9m76enoh8XiS4wC6191jqE2SJtrIQ6GqvgI8muSVXdMZ9J79fDOwsWvbCNw06tokadItH9N23wV8NMnhwBeBt9MLqOuSXAg8Apw3ptokaWKNJRSq6i5geo5ZZ4y4FElSH+9oliQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1IwtFJIsS/KFJP+9mz4myS1JHupeV4yrNkmaVOM8Ung38EDf9MXAtqpaB2zrpiVJIzSWUEiyBvgJ4EN9zeuBrd37rcC5Iy5LkibeuI4Ufgf4ZeCZvrZjq2oXQPe6aq4PJtmUZCbJzOzs7NALlaRJMvJQSPKTwO6qunM+n6+qLVU1XVXTU1NTC1ydJE225WPY5huAc5KcDbwQOCrJfwUeT3JcVe1Kchywewy1SdJEG/mRQlVdUlVrqmotsAH486q6ALgZ2NgtthG4adS1SdKkO5TuU7gMeFOSh4A3ddOSpBEax+mjpqo+BXyqe/9V4Ixx1iNJk+5QOlKQJI2ZoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNeN4RvPxSf53kgeSbE/y7q79mCS3JHmoe10x6tokadKN40hhD/DvquqHgNOAi5KcBFwMbKuqdcC2blqSNELjeEbzrqr6fPf+74AHgNXAemBrt9hW4NxR1yZJk26s1xSSrAVeA9wOHFtVu6AXHMCqMZYmSRNpbKGQ5MXADcAvVNXXn8fnNiWZSTIzOzs7vAIlaQKNJRSSvIBeIHy0qm7smh9Pclw3/zhg91yfraotVTVdVdNTU1OjKViSJsQ4vn0U4MPAA1X1n/tm3Qxs7N5vBG4adW2SNOmWj2GbbwB+Brg3yV1d23uBy4DrklwIPAKcN4baJGmijTwUqur/ANnP7DNGWYsk6Xt5R7MkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYdcKCQ5K8mDSXYkuXjc9UjSJDmkQiHJMuD3gTcDJwHnJzlpvFVJ0uQ4pEIBOBXYUVVfrKpvA9cC68dckyRNjJE/o/kAVgOP9k3vBP5J/wJJNgGbusm/T/LgQWxvJfDEQXx+XvKBUW+xGUt/x8w+T4aJ63M+cFB9ftn+ZhxqoZA52up7Jqq2AFsWZGPJTFVNL8S6FoNJ6y/Y50lhnxfOoXb6aCdwfN/0GuCxMdUiSRPnUAuFzwHrkpyQ5HBgA3DzmGuSpIlxSJ0+qqo9SX4O+ASwDLiyqrYPcZMLchpqEZm0/oJ9nhT2eYGkqg68lCRpIhxqp48kSWNkKEiSmiUfCgcaNiM9v9vNvyfJa8dR50IaoM8/3fX1niSfSfLqcdS5kAYdHiXJ65I8neSto6xvGAbpc5I3JrkryfYknx51jQttgL/tf5DkT5Pc3fX57eOoc6EkuTLJ7iT37Wf+wu+/qmrJ/tC7WP3/gBOBw4G7gZP2WeZs4M/o3SNxGnD7uOseQZ9fD6zo3r95Evrct9yfA/8TeOu46x7B7/lo4H7gB7rpVeOuewR9fi/wge79FPAkcPi4az+IPv8o8Frgvv3MX/D911I/Uhhk2Iz1wEeq5zbg6CTHjbrQBXTAPlfVZ6rqb7rJ2+jdD7KYDTo8yruAG4DdoyxuSAbp878CbqyqRwCqarH3e5A+F3BkkgAvphcKe0Zb5sKpqlvp9WF/Fnz/tdRDYa5hM1bPY5nF5Pn250J6/2ksZgfsc5LVwL8E/nCEdQ3TIL/nVwArknwqyZ1J3jay6oZjkD7/HvBD9G56vRd4d1U9M5ryxmLB91+H1H0KQ3DAYTMGXGYxGbg/SX6MXij8s6FWNHyD9Pl3gPdU1dO9fyIXvUH6vBz4YeAM4PuAzya5rar+atjFDckgfT4TuAs4HXg5cEuSv6iqrw+5tnFZ8P3XUg+FQYbNWGpDawzUnySnAB8C3lxVXx1RbcMySJ+ngWu7QFgJnJ1kT1V9bCQVLrxB/7afqKpvAN9IcivwamCxhsIgfX47cFn1TrjvSPIw8IPAHaMpceQWfP+11E8fDTJsxs3A27qr+KcBf1tVu0Zd6AI6YJ+T/ABwI/Azi/i/xn4H7HNVnVBVa6tqLXA98G8XcSDAYH/bNwE/kmR5khfRG3H4gRHXuZAG6fMj9I6MSHIs8ErgiyOtcrQWfP+1pI8Uaj/DZiR5Zzf/D+l9E+VsYAfwTXr/aSxaA/b5fcBLgCu6/5z31CIeYXLAPi8pg/S5qh5I8nHgHuAZ4ENVNedXGxeDAX/Pvw5cneReeqdW3lNVi3ZI7STXAG8EVibZCVwKvACGt/9ymAtJUrPUTx9Jkp4HQ0GS1BgKkqTGUJAkNYaCJKkxFKQBJHl/kl8adx3SsBkKkqTGUJDmkORt3fj0dyf5433m/WySz3XzbujuFibJeUnu69pv7dpOTnJH90yDe5Ks69ov6Gv/oyTLup+ru3Xcm+QXR99zTTpvXpP2keRkesOAvKGqnkhyDPDzwN9X1W8lecne8aKS/Cfg8aq6vLuL9qyq+nKSo6vqa0kuB26rqo92QzMsA9YCvwG8paq+k+QKekOYb6c3bs+bunUfXVVfG23vNek8UpCe7XTg+r3DI1TVvuPZvyrJX3Qh8NPAyV37/6U3xMLP0tv5A3wWeG+S9wAvq6pv0Rub54eBzyW5q5s+kd4YPScmuTzJWcBSHdlThzBDQXq28NzDD18N/FxV/SPgPwAvBKiqdwK/Sm/Uyru6I4r/BpwDfAv4RJLTu/Vvrap/3P28sqre3z346NXAp4CL6I1iK42UoSA92zbgp5K8BKA7fdTvSGBXkhfQO1KgW+7lVXV7Vb0PeAI4PsmJwBer6nfpjWh5Srf+tyZZtXf9SV6WZCVwWFXdAPwavccwSiO1pEdJleajG3lzM/DpJE8DXwC+1LfIrwG3A39N7+leR3btv9ldSA69Hf/dwMXABUm+A3wF+I9V9WSSXwU+meQw4Dv0jgy+BVzVtQFcMsRuSnPyQrMkqfH0kSSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTm/wNoh+U/MJywhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of y=0:  0.5\n",
      "Percentage of y=1:  0.5\n"
     ]
    }
   ],
   "source": [
    "## is the training dataset balanced now? ##\n",
    "plt.hist(y_train)\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('counts')\n",
    "plt.show()\n",
    "\n",
    "print('Percentage of y=0: ',y_train[y_train==0].shape[0]/y_train.shape[0])\n",
    "print('Percentage of y=1: ',y_train[y_train==1].shape[0]/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of y=0:  0.18061674008810572\n",
      "Percentage of y=1:  0.8193832599118943\n"
     ]
    }
   ],
   "source": [
    "## what is the proportion of class 0/1 in the test set? ##\n",
    "plt.hist(y_test)\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('counts')\n",
    "plt.show()\n",
    "\n",
    "print('Percentage of y=0: ',y_test[y_test==0].shape[0]/y_test.shape[0])\n",
    "print('Percentage of y=1: ',y_test[y_test==1].shape[0]/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that now there are an equal number of samples for both classes in the training dataset.  Since our feature space is relatively small (30), we will not consider dimension reduction as part of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare the classifier and train the model ##\n",
    "clf = DecisionTreeClassifier(max_depth=5,loss='gini')\n",
    "clf.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate predictions ##\n",
    "yp = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n",
      "precision: 0.97\n",
      "recall: 0.90\n"
     ]
    }
   ],
   "source": [
    "## evaluate model performance ##\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test,yp))\n",
    "print(\"precision: %.2f\" % precision_score(y_test,yp))\n",
    "print(\"recall: %.2f\" % recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below let's compare with the results from the scikit-learn decision tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the scikit-learn model ##\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## declare the classifier and train the model ##\n",
    "clf = DecisionTreeClassifier(max_depth=5,criterion='gini')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate predictions ##\n",
    "yp = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90\n",
      "precision: 0.98\n",
      "recall: 0.90\n"
     ]
    }
   ],
   "source": [
    "## evaluate model performance ##\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test,yp))\n",
    "print(\"precision: %.2f\" % precision_score(y_test,yp))\n",
    "print(\"recall: %.2f\" % recall_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tabulate the classifier results:\n",
    "\n",
    "Model | Impurity Metric | Depth | Accuracy | Precision | Recall\n",
    "-- | -- | -- | -- | -- | --\n",
    "Custom | Gini | 5 | 0.93 | 0.98 | 0.93\n",
    "Scikit | Gini | 5 | 0.93 | 0.98 | 0.93\n",
    "Custom | Entropy | 5 | 0.93 | 0.97 | 0.95\n",
    "Scikit | Entropy | 5 | 0.92 | 0.98 | 0.92\n",
    "Custom | Gini | 10 | 0.90 | 0.98 | 0.90\n",
    "Scikit | Gini | 10 | 0.93 | 0.98 | 0.93\n",
    "Custom | Entropy | 10 | 0.91 | 0.98 | 0.91\n",
    "Scikit | Entropy | 10 | 0.91 | 0.96 | 0.93\n",
    "\n",
    "The results indicate the scikit-learn model and our custom built classifier are roughly compariable for all hyperparameter configurations attempted. Note the model shows signs of overfitting when the maximum tree depth is set to 10. Let's move on to test the performance of our regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model\n",
    "\n",
    "We can check the performance of the regression tree model on a dummy dataset generated using the make_regression function from scikit-learn.  The dataset will consist of 8 features in total, 5 of which will be informative for the single target.  The standard deviation in the noise is set to 1, and a total of 1000 samples is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a regression dataset ##\n",
    "X,y = make_regression(n_samples=1000, n_features=8, n_informative=5, n_targets=1, noise=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do train/test split ##\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare the regressor and train the model ##\n",
    "rgr = DecisionTreeRegressor(max_depth=5,loss='mae')\n",
    "rgr.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions ##\n",
    "yp = rgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 70.04\n",
      "mae: 56.44\n",
      "r2: 0.68\n"
     ]
    }
   ],
   "source": [
    "## evaluate model performance ##\n",
    "print(\"rmse: %.2f\" % np.sqrt(mean_squared_error(y_test,yp)))\n",
    "print(\"mae: %.2f\" % mean_absolute_error(y_test,yp))\n",
    "print(\"r2: %.2f\" % r2_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the scikit-learn model ##\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mae', max_depth=5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## declare the regressor and train the model ##\n",
    "rgr = DecisionTreeRegressor(max_depth=5,criterion='mae')\n",
    "rgr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions ##\n",
    "yp = rgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 63.68\n",
      "mae: 49.35\n",
      "r2: 0.74\n"
     ]
    }
   ],
   "source": [
    "## evaluate model performance ##\n",
    "print(\"rmse: %.2f\" % np.sqrt(mean_squared_error(y_test,yp)))\n",
    "print(\"mae: %.2f\" % mean_absolute_error(y_test,yp))\n",
    "print(\"r2: %.2f\" % r2_score(y_test,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tabulate the regressor results:\n",
    "\n",
    "Model | Impurity Metric | Depth | RMSE | MAE' | R2\n",
    "-- | -- | -- | -- | -- | --\n",
    "Custom | MSE | 5 | 69.05 | 55.91 | 0.69\n",
    "Scikit | MSE | 5 | 66.31 | 53.61 | 0.71\n",
    "Custom | MAE | 5 | 70.04 | 56.44 | 0.68\n",
    "Scikit | MAE | 5 | 63.68 | 49.35 | 0.74\n",
    "Custom | MSE | 10 | 64.07 | 48.85 | 0.73\n",
    "Scikit | MSE | 10 | 59.72 | 45.56 | 0.77\n",
    "Custom | MAE | 10 | 55.53 | 41.88 | 0.80\n",
    "Scikit | MAE | 10 | 56.09 | 42.19 | 0.80\n",
    "\n",
    "Note that the mean absolute error is calculated differently for the impurity metric (MAE) versus evaluation metric (MAE'): \n",
    "* The impurity metric is computed with respect to the mean of the label values for any given node in the tree\n",
    "* The evaluation metric is computed by taking the difference between predicted and actual label values for the entire test set\n",
    "\n",
    "For 3/4 of the configurations tested, the scikit-learn regressor outperforms our custom built model. This is notable for the {impurity = MAE, depth = 5} and {impurity = MSE, depth = 10} configurations.  \n",
    "\n",
    "The custom built model performs better for the {impurity = MAE, depth = 10} configuration, however. This is also the best performing model overall.\n",
    "\n",
    "To improve performance of the custom built model, feel free to try replacing the mean (y_m) in the private impurity functions with the median. You can also try using deeper trees, since overfitting does not appear to be an issue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
