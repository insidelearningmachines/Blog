{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ed3613-ed34-4aab-9ec9-b10e13ad716e",
   "metadata": {},
   "source": [
    "# The Weighted PageRank Algorithm\n",
    "\n",
    "In this notebook, we'll cover an implementation of the Weighted PageRank algorithm. In the example here, we will be working exclusively with a directed graph.\n",
    "\n",
    "PageRank was originally developed at Google by Larry Page and Sergey Brin. This algorithm is famous for being the original basis for the Google Search Engine. See: https://www.cis.upenn.edu/~mkearns/teaching/NetworkedLife/pagerank.pdf?ref=ruky.me\n",
    "\n",
    "Here we will build upon the \"vanilla\" PageRank, where each edge is given equal importance when traversing a graph. In Weighted PageRank, the edges in a graph are given different levels of importance, or \"weights\", when traversing said graph. You can refer to this paper for more technical details on Weighted PageRank: http://delab.csd.auth.gr/~dimitris/courses/ir_spring06/page_rank_computing/01344743.pdf\n",
    "\n",
    "Please refer to my previous notebook on PageRank here: https://github.com/insidelearningmachines/Blog/blob/main/Notebook%20XXIX%20Learn%20the%20PageRank%20Algorithm%20with%201%20Simple%20Example.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182a6aad-6a2a-4501-a3b7-962686cf3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknetwork as skn\n",
    "import numpy as np\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4250e1-820a-44b1-ac23-94b150d0b599",
   "metadata": {},
   "source": [
    "And now we can run the notebook from the original PageRank post to load in the objects implemented there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf91bdb-cc39-4782-a568-4b7f9ac2b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Notebook\\ XXIX\\ Learn\\ the\\ PageRank\\ Algorithm\\ with\\ 1\\ Simple\\ Example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95eab440-4ca5-427f-9c42-32e0664e53c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'),\n",
       " ('B', 'D'),\n",
       " ('D', 'A'),\n",
       " ('D', 'C'),\n",
       " ('A', 'C'),\n",
       " ('C', 'A'),\n",
       " ('D', 'E'),\n",
       " ('F', 'D')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the edges imported from the XXIX notebook\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74eff8ef-137f-4a3d-8335-e245b196d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = skn.data.from_edge_list(edges, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3977142-5000-4ad7-8b30-fb8cf14bb0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"452.0\" height=\"352\">\n",
       "<defs><marker id=\"arrow-gray\" markerWidth=\"10\" markerHeight=\"10\" refX=\"9\" refY=\"3\" orient=\"auto\">\n",
       "<path d=\"M0,0 L0,6 L9,3 z\" fill=\"gray\"/></marker></defs>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 426 146 405 289\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 426 146 377 38\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 404 295 231 183\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 375 32 424 140\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 226 180 420 147\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 226 180 371 36\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 226 180 32 66\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 60 332 221 184\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<circle cx=\"426\" cy=\"146\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"404\" cy=\"295\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"375\" cy=\"32\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"226\" cy=\"180\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"26\" cy=\"63\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"60\" cy=\"332\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<text text-anchor=\"middle\" x=\"426\" y=\"136\" font-size=\"12\">A</text><text text-anchor=\"middle\" x=\"404\" y=\"285\" font-size=\"12\">B</text><text text-anchor=\"middle\" x=\"375\" y=\"22\" font-size=\"12\">C</text><text text-anchor=\"middle\" x=\"226\" y=\"170\" font-size=\"12\">D</text><text text-anchor=\"middle\" x=\"26\" y=\"53\" font-size=\"12\">E</text><text text-anchor=\"middle\" x=\"60\" y=\"322\" font-size=\"12\">F</text></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = skn.visualization.graphs.visualize_graph(adjacency=graph.adjacency, names=graph.names, name_position='above')\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a7d96-d57d-4537-bc07-aaa1b60103e4",
   "metadata": {},
   "source": [
    "## The Algorithm\n",
    "\n",
    "We saw in the previous post the update rule for PageRank over iteration $t=0,1,2,...$:\n",
    "\n",
    "${\\bf P_r(t+1)} = d{\\bf \\hat{O}P_r(t)} + \\frac{1-d}{N_p}{\\bf 1}$\n",
    "\n",
    "where:\n",
    "\n",
    "* $d$ is the damping factor\n",
    "* $N_p$ is the number of nodes (i.e. webpages) in the graph\n",
    "* ${\\bf P_r(t)}$ is a column vector containing all the page ranks at step $t$\n",
    "* ${\\bf D}$ is a square diagonal matrix, where each element along the diagonal is either the inverse of the out-degree of node $i$, or $0.0$ if there are no outgoing edges\n",
    "* ${\\bf O}$ is the square adacency matrix for the graph\n",
    "* ${\\bf \\hat{O}}$ is a modified form of the adacency matrix, where each element $\\hat{O}_{i,j}$ is the ratio of edges from $j \\rightarrow i$ divided by the total out-degree of node $j$\n",
    "* ${\\bf 1}$ is a column vector consisting of $N_p$ elements all set to 1.0\n",
    "\n",
    "We can continue updating until convergence is reached as set by a tolerance parameter $\\epsilon$:\n",
    "\n",
    "$|{\\bf P_r(t+1)} - {\\bf P_r(t)}| < \\epsilon$\n",
    "\n",
    "For <u>Weighted PageRank</u>, we replace ${\\bf \\hat{O}}$ with a weights matrix ${\\bf W}$ in our update rule such that:\n",
    "\n",
    "${\\bf P_r(t+1)} = d{\\bf WP_r(t)} + \\frac{1-d}{N_p}{\\bf 1}$\n",
    "\n",
    "and\n",
    "\n",
    "${\\bf W} = \\begin{bmatrix} w_{0,0} && w_{0,1} && \\cdots && w_{0,N_p} \\\\ \n",
    "                           w_{1,0} && w_{1,1} &&        && \\vdots \\\\\n",
    "                           \\vdots    &&           && \\ddots &&        \\\\\n",
    "                           w_{N_p,0} && \\cdots  &&        && w_{N_p,N_p} \\end{bmatrix}$\n",
    "\n",
    "where each element $w_{i,j}$ is the weight for the edge connecting nodes $j \\rightarrow i$, and can take on a value between $[0.0,1.0]$. \n",
    "\n",
    "**Technically, ${\\bf W}$ can be computed any way in which you desire to weight the edges. The choice for how you determine the weights will depend on the problem you're working on.**\n",
    "\n",
    "For the specific case of web pages, we can determine each element of ${\\bf W}$ by first computing:\n",
    "\n",
    "$w_{i,j} = w^{in}_{j \\rightarrow i} \\times w^{out}_{j \\rightarrow i}$\n",
    "\n",
    "where: \n",
    "\n",
    "$w^{in}_{j \\rightarrow i} = \\frac{\\textrm{number of incoming edges for} \\: i}{\\textrm{sum of all incoming edges for all nodes that link with} \\: j}$\n",
    "\n",
    "$w^{out}_{j \\rightarrow i} = \\frac{\\textrm{number of outgoing edges for} \\: i}{\\textrm{sum of all outgoing edges for all nodes that link with} \\: j}$\n",
    "\n",
    "After computing each of these elements we can normalize the weights, with respect to all the outgoing edges from node $j$, to arrive at matrix ${\\bf W}$.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Let's now proceed to implement the algorithm covered above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa83cb7-7523-40cb-9bbe-3be554663a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedGraph(Graph):\n",
    "\n",
    "    def _build_weight_matrix(self) -> np.array:\n",
    "        W = np.zeros((len(self.nodes),len(self.nodes)))\n",
    "        edges = np.array(self.edges)\n",
    "        for node in self.nodes:\n",
    "            # get all outgoing link nodes from node\n",
    "            out_nodes = np.unique(edges[edges[:,0] == node][:,1])\n",
    "            # get counts of incoming and outgoing links for all out_nodes\n",
    "            I = np.array(list(map(self.indegrees.get, out_nodes)))\n",
    "            I[I == None] = 0\n",
    "            O = np.array(list(map(self.outdegrees.get, out_nodes)))\n",
    "            O[O == None] = 0\n",
    "            # compute weight components\n",
    "            w_in = I/np.sum(I)\n",
    "            w_out = O/np.sum(O)\n",
    "            # fill in weights matrix\n",
    "            col_idx = [self.nodes.index(node) for node in out_nodes]\n",
    "            W[self.nodes.index(node),col_idx] = w_in*w_out\n",
    "        return W\n",
    "\n",
    "    def get_weighted_adjacency_matrix(self) -> np.array:\n",
    "        # get the raw weight matrix\n",
    "        W = self._build_weight_matrix()\n",
    "        # normalize weights & return\n",
    "        denominator = np.sum(W,axis=1)\n",
    "        denominator = np.where(denominator == 0, 1., denominator)\n",
    "        return (W.T/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb420dc-3cdb-41ea-b747-859067bc853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedPageRank(PageRank):\n",
    "\n",
    "    def _step(self, P1: np.array, I: np.array, graph: Graph) -> np.array:\n",
    "        P2 = (\n",
    "            self.damping_factor*np.matmul(graph.get_weighted_adjacency_matrix(),P1) \n",
    "            + (1 - self.damping_factor)*I/graph.get_number_nodes()\n",
    "        )\n",
    "        return(P2/np.sum(P2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02922dc-4b15-40ae-87c4-dd4bff338591",
   "metadata": {},
   "source": [
    "## Run the Weighted PageRank\n",
    "\n",
    "Here let's test out the classes we just implemented, to see if the results make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beaf02f0-b21a-4c10-8dc3-6b2aaa5c11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph object\n",
    "graph = WeightedGraph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6311e46e-f689-4b85-9d86-9216ad588753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.66666667, 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_weighted_adjacency_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342b22b-fa5f-43b4-9068-5684438a7980",
   "metadata": {},
   "source": [
    "Each column shows the fraction of the page rank that is distributed to other nodes at each iteration $t$. For example, the first column shows how the page rank of node A is distributed: 33.3% goes to node B, while 66.7% goes to node C.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a588f3c-a217-4130-ad8e-60b30a9898e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pagerank object\n",
    "pr = WeightedPageRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2735326-d44a-4e50-b658-02da34ced17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pageranks\n",
    "ranks = pr.evaluate(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "233696b3-8497-4ab0-a8f9-5c6c7ad6a14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.3681734599108074,\n",
       " 'B': 0.132187163250422,\n",
       " 'C': 0.2859159868057953,\n",
       " 'D': 0.16261318236879824,\n",
       " 'E': 0.025555103832088505,\n",
       " 'F': 0.025555103832088505}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ab3d6-7900-442a-a955-662f0b2831af",
   "metadata": {},
   "source": [
    "Node | Original PageRank | Weighted PageRank\n",
    "--- | --- | ---\n",
    "A | 0.295 | 0.368\n",
    "B | 0.163 | 0.132\n",
    "C | 0.224 | 0.286\n",
    "D | 0.202 | 0.163\n",
    "E | 0.089 | 0.025\n",
    "F | 0.027 | 0.025\n",
    "\n",
    "Here we can see how the edge weights effect the ranking results. Some of the most notable changes is the increase in page rank to nodes A and C, whereas nodes B and D see a decrease. Node D is peculiar, in that it is linked to a dangling node (E). I covered dangling nodes in a recent video (https://www.youtube.com/watch?v=LSRgw7QE8Uk). The presence of such nodes will certainly effect the results, and as such if we properly treat for E, the rankings for both D and E will likely change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
