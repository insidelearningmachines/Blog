{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892d4c10-ff0a-490f-82c7-7f032805ad24",
   "metadata": {},
   "source": [
    "# 3 Methods for Hyperparameter Tuning with Random Forest\n",
    "\n",
    "In this notebook, we'll explore 3 different approaches for hyperparameter tuning with a Random Forest classifier. These will include:\n",
    "\n",
    "1. **Grid Search** : cycle through every configuration in a predetermined set of parameter values\n",
    "2. **Randomized Search** : randomly select configurations from a set of parameter distributions\n",
    "3. **Bayesian Optimisation** : select configurations based on prior distributions for each parameter\n",
    "\n",
    "There are numerous different hyperparameters available for Random Forest. A complete listing of these parameters for the scikit-learn implementation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html. For the purpose of our work here, I'll only consider tuning the following:\n",
    "\n",
    "* *criterion* : function used to measure quality of splits\n",
    "* *n_estimators* : number of trees to include in the ensemble\n",
    "* *max_depth* : maximum number of splits per tree\n",
    "* *min_samples_split* : minimum number of samples in a node for a split to occur\n",
    "* *min_samples_leaf* : minimum samples in a node for it to be considered a leaf node\n",
    "* *max_features* : function used to determine number of features to consider when doing a split\n",
    "\n",
    "For this demonstration, we will create a toy dataset using scikit-learn's *make_classification*. \n",
    "\n",
    "We can start by importing the packages necessary here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a344ae-f5d0-46a9-a742-cd28b2f93a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "from scipy.stats import poisson, randint\n",
    "import numpy as np\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c8375-ddda-4779-b4a6-e61b216c70d6",
   "metadata": {},
   "source": [
    "Now let's create our dataset, and do a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53953757-0627-4a51-a36d-4506a59b673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in and prepare data\n",
    "X, y = make_classification(n_samples=5000, \n",
    "                           n_features=100, \n",
    "                           n_informative=50,\n",
    "                           n_classes=2, \n",
    "                           weights=[0.6,0.4],\n",
    "                           random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0a23fc-2c64-45ef-9ff2-99b250d53014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def print_results(clf: Callable, X_test: np.array, y_test: np.array) -> None:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    print(f'accuracy score: {accuracy_score(y_test, y_pred):.2f}')\n",
    "    print(f\"precision score: {precision_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"recall score: {recall_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"f1 score: {f1_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"ROC AUC score: {roc_auc_score(y_test, y_prob[:,1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f626b-01ed-43ac-a627-e9b113b6707c",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "To be able to measure the effects of our tuning, let's first measure how well Random Forest does on the test set with all default hyperparameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6482e9-8cd3-424f-a468-804bf315f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.88\n",
      "precision score: 0.96\n",
      "recall score: 0.72\n",
      "f1 score: 0.83\n",
      "ROC AUC score: 0.9547358510304426\n",
      "CPU times: user 1.79 s, sys: 7.59 ms, total: 1.8 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit a model with default parameters\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# compute performance on test set\n",
    "print_results(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fc7e3-baaa-4307-bfe9-b16c07a77a7b",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "Brute force approach to hyperparameter tuning. Each parameter configuration will be validated using 5-fold Cross-Validation. Afterwards, the best model will be selected, and tested against our held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e966ef-a496-4be3-a554-b5ccbd008cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 1.96 s, total: 18.9 s\n",
      "Wall time: 32min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# setup parameter space\n",
    "parameters = {\n",
    "    'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'n_estimators':[50, 100, 500],\n",
    "    'max_depth':[1, 5, 10, 15],\n",
    "    'min_samples_split':[2, 4, 6, 8],\n",
    "    'min_samples_leaf':[1, 2, 3, 4],\n",
    "    'max_features':[\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# create an instance of the grid search object\n",
    "g = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# conduct grid search over the parameter space\n",
    "g.fit(X_train, y_train)\n",
    "\n",
    "# show best parameter configuration found for classifier\n",
    "cls_params = g.best_params_\n",
    "cls_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805fd7df-bdc9-4e76-889d-8df06faedde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.88\n",
      "precision score: 0.97\n",
      "recall score: 0.73\n",
      "f1 score: 0.83\n",
      "ROC AUC score: 0.9658667224605083\n"
     ]
    }
   ],
   "source": [
    "# compute performance on test set\n",
    "print_results(g.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ba4c5-661b-420a-abcc-3cf7dcffb92b",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "We can do hyperparameter tuning through random sampling from a probability distribution, for non-categorical hyperparameters. Each parameter configuration will be validated using 5-fold Cross-Validation. Afterwards, the best model will be selected, and tested against our held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18633a5f-7156-4c11-9d3a-f62f6c0f253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.89 s, sys: 57.9 ms, total: 7.95 s\n",
      "Wall time: 52.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 14,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 487}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# setup parameter space\n",
    "parameters = {\n",
    "    'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'n_estimators':poisson(mu=500),\n",
    "    'max_depth':poisson(mu=10),\n",
    "    'min_samples_split':randint(low=2, high=5),\n",
    "    'min_samples_leaf':randint(low=1, high=5),\n",
    "    'max_features':[\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# create an instance of the randomized search object\n",
    "r = RandomizedSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5, n_iter=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# conduct grid search over the parameter space\n",
    "r.fit(X_train,y_train)\n",
    "\n",
    "# show best parameter configuration found for classifier\n",
    "cls_params2 = r.best_params_\n",
    "cls_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc13652-af48-46f4-aa04-7500e3d47858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.89\n",
      "precision score: 0.98\n",
      "recall score: 0.73\n",
      "f1 score: 0.84\n",
      "ROC AUC score: 0.9621090072183283\n"
     ]
    }
   ],
   "source": [
    "# compute performance on test set\n",
    "print_results(r.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1893b3-717a-4d99-a5a6-a4c91bcbe327",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "The final method we'll try takes advantage of Bayes theorem for hyperparameter tuning. Like before, the search space for non-categorical hyperparameters is defined by a set of probability distributions, in this case in the form of priors. Care will be needed when selecting these prior distributions. Each parameter configuration will be validated using 5-fold Cross-Validation. Afterwards, the best model will be selected, and tested against our held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09652b99-3fd4-404d-b261-759ca02166b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.86 s, sys: 60.4 ms, total: 9.92 s\n",
      "Wall time: 58.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('criterion', 'entropy'),\n",
       "             ('max_depth', 18),\n",
       "             ('max_features', 'sqrt'),\n",
       "             ('min_samples_leaf', 2),\n",
       "             ('min_samples_split', 2),\n",
       "             ('n_estimators', 481)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# setup parameter space\n",
    "parameters = {\n",
    "    'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'n_estimators':Integer(50,1000,prior='uniform'),\n",
    "    'max_depth':Integer(1,20,prior='uniform'),\n",
    "    'min_samples_split':Integer(2,5,prior='log-uniform'),\n",
    "    'min_samples_leaf':Integer(1,5,prior='log-uniform'),\n",
    "    'max_features':[\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# create an instance of the bayesian search object\n",
    "b = BayesSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5, n_iter=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# conduct randomized search over the parameter space\n",
    "b.fit(X_train,y_train)\n",
    "\n",
    "# show best parameter configuration found for classifier\n",
    "cls_params3 = b.best_params_\n",
    "cls_params3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6979b29a-18e2-4f03-9839-85c02105f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.89\n",
      "precision score: 0.98\n",
      "recall score: 0.74\n",
      "f1 score: 0.84\n",
      "ROC AUC score: 0.9657453708546919\n"
     ]
    }
   ],
   "source": [
    "# compute performance on test set\n",
    "print_results(b.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166088d1-09dc-4f2b-9529-1df41b48b689",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have tested out 6 key hyperparameters for Random Forest, using 3 popular techniques for parameter tuning. All results listed below are dependent on the dataset used in this notebook: \n",
    "\n",
    "* Bayesian optimization takes a bit longer to run than Randomized Search, but the Bayesian approach yields slightly better results for the same number of iterations.\n",
    "* Both Randomized Search and Bayesian Optimization benefit from being able to handle distributions for their non-categorical hyperparameters.\n",
    "* Grid Search is by far the slowest method, and suffers from needing the parameters defined in an array (as opposed to a distribution). Yields results that are somewhat better than the baseline!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6ecb3-5844-46c2-8f3b-726ed049d59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
