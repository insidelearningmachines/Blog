{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197ae0cd",
   "metadata": {},
   "source": [
    "# KNN Recommender System\n",
    "\n",
    "In this notebook, I will work through the application of KNN to recommendation. This implmentation will fall within the scope of collaborative filtering. I will make use of the MovieLens ml-25m dataset. \n",
    "\n",
    "The dataset describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 25000095 ratings and 1093360 tag applications across 62423 movies. These data were created by 162541 users between January 09, 1995 and November 21, 2019. This dataset was generated on November 21, 2019.\n",
    "\n",
    "\n",
    "Reference:\n",
    "\n",
    "* F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9ae145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13bc3d5",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data Files\n",
    "\n",
    "The data are contained in files 'genome-scores.csv', 'genome-tags.csv', 'links.csv', 'movies.csv', 'ratings.csv' and 'tags.csv'. Let's load these into our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83df7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "dfRatings = pd.read_csv('./ml-25m/ratings.csv')\n",
    "dfTags    = pd.read_csv('./ml-25m/tags.csv')\n",
    "dfMovies  = pd.read_csv('./ml-25m/movies.csv')\n",
    "dfLinks   = pd.read_csv('./ml-25m/links.csv')\n",
    "dfGscores = pd.read_csv('./ml-25m/genome-scores.csv')\n",
    "dfGtags   = pd.read_csv('./ml-25m/genome-tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61a92d",
   "metadata": {},
   "source": [
    "In a previous article on *data pipelines*, we already constructed a set of stage functions for all the preprocessing steps. Let's implement them below, and prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline stages ##\n",
    "def prepare_ratings(dfRatings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to preprocess ratings dataframe\n",
    "    \n",
    "    Inputs:\n",
    "        dfRatings -> dataframe containing ratings information\n",
    "        \n",
    "    Outputs:\n",
    "        ratings dataframe without timestamp column \n",
    "    \"\"\"\n",
    "    dfRatings.drop(['timestamp'],axis=1,inplace=True)\n",
    "    return dfRatings\n",
    "\n",
    "def prepare_tags(dfRatings: pd.DataFrame,\n",
    "                 dfTags: pd.DataFrame, \n",
    "                 dfGtags: pd.DataFrame, \n",
    "                 dfGscores: pd.DataFrame, \n",
    "                 threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to execute preprocessing on the tags dataframes\n",
    "    \n",
    "    Inputs:\n",
    "        dfRatings -> dataframe containing ratings information\n",
    "        dfTags    -> dataframe containing tags information\n",
    "        dfGtags   -> dataframe containing tag genome information\n",
    "        dfGscores -> dataframe containing tag relevance information\n",
    "        thresold  -> cutoff threshold based upon tag popularity\n",
    "        \n",
    "    Output:\n",
    "        dataframe containing the prepared tags features merged to dfRatings\n",
    "    \"\"\"\n",
    "    # drop timestamp column\n",
    "    dfTags.drop(['timestamp'],axis=1,inplace=True)\n",
    "    \n",
    "    # set tags to lower case\n",
    "    dfTags['tag'] = dfTags.tag.str.lower()\n",
    "    dfGtags['tag'] = dfGtags.tag.str.lower()\n",
    "\n",
    "    # join dfTags, dfGtags, & dfGscores\n",
    "    dfTagScores = pd.merge(dfTags,dfGtags,on='tag')\n",
    "    dfTagScores = pd.merge(dfTagScores,dfGscores,on=['movieId','tagId'])\n",
    "    \n",
    "    # extract usable tagId's based on cutoff threshold\n",
    "    dfTagIds = dfTagScores[['userId','tagId']].copy()\n",
    "    dfTagIds.drop_duplicates(inplace=True)\n",
    "    dfTagIds['occurance'] = 1\n",
    "    sTagIds = dfTagIds.groupby(by=['tagId'])['occurance'].sum().sort_values(ascending=False)\n",
    "    tagIds = sTagIds[:threshold].index\n",
    "    \n",
    "    # OHE the tags, then multiply in the relevance\n",
    "    sTags = dfTagScores[dfTagScores.tagId.isin(tagIds)].tag\n",
    "    dfOHE = pd.get_dummies(sTags)\n",
    "    dfTagsOHE = dfOHE.mul(dfTagScores.relevance,axis=0)\n",
    "    \n",
    "    # do final assembly of tags dataframe\n",
    "    dfTags = pd.concat([dfTagScores[['userId','movieId','tagId']],dfTagsOHE],axis=1)\n",
    "    \n",
    "    # return merged results\n",
    "    return pd.merge(dfRatings,dfTags,on=['userId','movieId'])\n",
    "\n",
    "def prepare_movies(dfRatings: pd.DataFrame,\n",
    "                   dfMovies: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    function to execute preprocessing on the movies dataframe\n",
    "    \n",
    "    Inputs:\n",
    "        dfRatings -> dataframe containing ratings information\n",
    "        dfMovies  -> dataframe containing movies-genre information\n",
    "        \n",
    "    Output:\n",
    "        dataframe containing the prepared movies-genre features merged to dfRatings\n",
    "    \"\"\"\n",
    "    # helper function for use when creating genre features\n",
    "    def flag_genre(row):\n",
    "        applicable_genres = row['genres'].split('|')\n",
    "        for genre in applicable_genres:\n",
    "            row[genre] = 1\n",
    "        return row\n",
    "    \n",
    "    # obtain the unique set of genres \n",
    "    raw_genres = dfMovies.genres.unique()\n",
    "    genres     = [g.split('|') for g in raw_genres]\n",
    "    genres     = list(set(chain(*genres)))\n",
    "    \n",
    "    # create a set of binary features for each genre\n",
    "    dfGenres = pd.DataFrame(0,columns=genres,index=np.arange(dfMovies.shape[0]))\n",
    "    dfMovies = pd.concat([dfMovies, dfGenres], axis=1, join='inner')\n",
    "    dfMovies = dfMovies.apply(flag_genre, axis=1)\n",
    "    \n",
    "    #drop irrelevant columns\n",
    "    dfMovies.drop(['title','genres'],axis=1,inplace=True)\n",
    "    \n",
    "    # merge and multiply through the ratings score\n",
    "    dfOut               = pd.merge(dfRatings,dfMovies,on='movieId')\n",
    "    dfOut.loc[:,genres] = dfOut[genres].mul(dfOut.rating,axis=0)\n",
    "    \n",
    "    # return\n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ffe161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cutoff threshold\n",
    "threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa61cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a pipeline to carry out the preprocessing work outlined previously\n",
    "dfPrepared = dfRatings.pipe(prepare_ratings) \\\n",
    "                      .pipe(prepare_tags,dfTags=dfTags,dfGtags=dfGtags,dfGscores=dfGscores,threshold=threshold) \\\n",
    "                      .pipe(prepare_movies,dfMovies=dfMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212d0e5",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Let's extract a small test set to be held out from the subsequent feature engineering & training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e180ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 5% of the user movie ratings\n",
    "dfSelected = dfPrepared[['userId','movieId']].drop_duplicates().sample(frac=0.05,random_state=42).copy()\n",
    "dfTest = pd.merge(dfPrepared,dfSelected,on=['userId','movieId'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bebf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the test set to form a training set\n",
    "dfTrainRaw = dfPrepared.drop(dfSelected.index.values).copy()\n",
    "dfTrain = dfTrainRaw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5190a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>tagId</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>aliens</th>\n",
       "      <th>alternate reality</th>\n",
       "      <th>animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Western</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Musical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264</td>\n",
       "      <td>260</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>260</td>\n",
       "      <td>3.0</td>\n",
       "      <td>942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>260</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  tagId  absurd  action  adventure   aliens  \\\n",
       "0       3      260     4.0    215     0.0     0.0        0.0  0.00000   \n",
       "1       3      260     4.0    887     0.0     0.0        0.0  0.00000   \n",
       "2     264      260     3.0     45     0.0     0.0        0.0  0.85675   \n",
       "3     264      260     3.0    942     0.0     0.0        0.0  0.00000   \n",
       "4     264      260     3.0    891     NaN     NaN        NaN      NaN   \n",
       "\n",
       "   alternate reality  animation  ...  Romance  IMAX  Western  Animation  \\\n",
       "0                0.0        0.0  ...      0.0   0.0      0.0        0.0   \n",
       "1                0.0        0.0  ...      0.0   0.0      0.0        0.0   \n",
       "2                0.0        0.0  ...      0.0   0.0      0.0        0.0   \n",
       "3                0.0        0.0  ...      0.0   0.0      0.0        0.0   \n",
       "4                NaN        NaN  ...      0.0   0.0      0.0        0.0   \n",
       "\n",
       "   Thriller  Comedy  (no genres listed)  Documentary  Film-Noir  Musical  \n",
       "0       0.0     0.0                 0.0          0.0        0.0      0.0  \n",
       "1       0.0     0.0                 0.0          0.0        0.0      0.0  \n",
       "2       0.0     0.0                 0.0          0.0        0.0      0.0  \n",
       "3       0.0     0.0                 0.0          0.0        0.0      0.0  \n",
       "4       0.0     0.0                 0.0          0.0        0.0      0.0  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the training dataframe\n",
    "dfTrain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee094",
   "metadata": {},
   "source": [
    "### Feature Engineering: Build User Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "dfTrain.drop(['movieId','tagId','rating'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35011122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby userId and sum\n",
    "dfTrain = dfTrain.groupby(by=['userId']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a176c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the dataframe\n",
    "dfTrain = dfTrain.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "694c7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise each user profile\n",
    "dfTrain = (dfTrain-dfTrain.mean())/dfTrain.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9032862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>19</th>\n",
       "      <th>68</th>\n",
       "      <th>87</th>\n",
       "      <th>91</th>\n",
       "      <th>93</th>\n",
       "      <th>95</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>...</th>\n",
       "      <th>162368</th>\n",
       "      <th>162390</th>\n",
       "      <th>162393</th>\n",
       "      <th>162400</th>\n",
       "      <th>162423</th>\n",
       "      <th>162440</th>\n",
       "      <th>162447</th>\n",
       "      <th>162462</th>\n",
       "      <th>162492</th>\n",
       "      <th>162501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>absurd</th>\n",
       "      <td>-0.125872</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>-0.155760</td>\n",
       "      <td>-0.124817</td>\n",
       "      <td>-0.154425</td>\n",
       "      <td>-0.177587</td>\n",
       "      <td>-0.103994</td>\n",
       "      <td>-0.079749</td>\n",
       "      <td>-0.167138</td>\n",
       "      <td>-0.171739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206357</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.199795</td>\n",
       "      <td>-0.142882</td>\n",
       "      <td>-0.102194</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.106208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>-0.125872</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>-0.155760</td>\n",
       "      <td>-0.124817</td>\n",
       "      <td>-0.154425</td>\n",
       "      <td>-0.111713</td>\n",
       "      <td>-0.103994</td>\n",
       "      <td>-0.079749</td>\n",
       "      <td>-0.167138</td>\n",
       "      <td>-0.171739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206357</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.160127</td>\n",
       "      <td>-0.142882</td>\n",
       "      <td>-0.102194</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.106208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adventure</th>\n",
       "      <td>-0.125872</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>-0.124817</td>\n",
       "      <td>-0.154425</td>\n",
       "      <td>-0.160101</td>\n",
       "      <td>-0.103994</td>\n",
       "      <td>-0.079749</td>\n",
       "      <td>-0.167138</td>\n",
       "      <td>-0.171739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206357</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.199795</td>\n",
       "      <td>-0.142882</td>\n",
       "      <td>-0.102194</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.106208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aliens</th>\n",
       "      <td>-0.125872</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>-0.155760</td>\n",
       "      <td>-0.124817</td>\n",
       "      <td>-0.006590</td>\n",
       "      <td>-0.169240</td>\n",
       "      <td>-0.103994</td>\n",
       "      <td>-0.079749</td>\n",
       "      <td>-0.167138</td>\n",
       "      <td>-0.171739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206357</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.199795</td>\n",
       "      <td>-0.142882</td>\n",
       "      <td>-0.102194</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.106208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternate reality</th>\n",
       "      <td>-0.125872</td>\n",
       "      <td>-0.165702</td>\n",
       "      <td>-0.155760</td>\n",
       "      <td>-0.124817</td>\n",
       "      <td>-0.154425</td>\n",
       "      <td>-0.168496</td>\n",
       "      <td>-0.103994</td>\n",
       "      <td>-0.079749</td>\n",
       "      <td>-0.167138</td>\n",
       "      <td>-0.171739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206357</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.095565</td>\n",
       "      <td>-0.199795</td>\n",
       "      <td>-0.142882</td>\n",
       "      <td>-0.102194</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-0.124032</td>\n",
       "      <td>-0.106208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId               3         4         19        68        87        91      \\\n",
       "absurd            -0.125872 -0.165702 -0.155760 -0.124817 -0.154425 -0.177587   \n",
       "action            -0.125872 -0.165702 -0.155760 -0.124817 -0.154425 -0.111713   \n",
       "adventure         -0.125872 -0.165702  0.022633 -0.124817 -0.154425 -0.160101   \n",
       "aliens            -0.125872 -0.165702 -0.155760 -0.124817 -0.006590 -0.169240   \n",
       "alternate reality -0.125872 -0.165702 -0.155760 -0.124817 -0.154425 -0.168496   \n",
       "\n",
       "userId               93        95        113       114     ...    162368  \\\n",
       "absurd            -0.103994 -0.079749 -0.167138 -0.171739  ... -0.206357   \n",
       "action            -0.103994 -0.079749 -0.167138 -0.171739  ... -0.206357   \n",
       "adventure         -0.103994 -0.079749 -0.167138 -0.171739  ... -0.206357   \n",
       "aliens            -0.103994 -0.079749 -0.167138 -0.171739  ... -0.206357   \n",
       "alternate reality -0.103994 -0.079749 -0.167138 -0.171739  ... -0.206357   \n",
       "\n",
       "userId               162390    162393    162400    162423    162440    162447  \\\n",
       "absurd            -0.139322 -0.095565 -0.199795 -0.142882 -0.102194 -0.125424   \n",
       "action            -0.139322 -0.095565 -0.160127 -0.142882 -0.102194 -0.125424   \n",
       "adventure         -0.139322 -0.095565 -0.199795 -0.142882 -0.102194 -0.125424   \n",
       "aliens            -0.139322 -0.095565 -0.199795 -0.142882 -0.102194 -0.125424   \n",
       "alternate reality -0.139322 -0.095565 -0.199795 -0.142882 -0.102194 -0.125424   \n",
       "\n",
       "userId               162462    162492    162501  \n",
       "absurd            -0.120977 -0.124032 -0.106208  \n",
       "action            -0.120977 -0.124032 -0.106208  \n",
       "adventure         -0.120977 -0.124032 -0.106208  \n",
       "aliens            -0.120977 -0.124032 -0.106208  \n",
       "alternate reality -0.120977 -0.124032 -0.106208  \n",
       "\n",
       "[5 rows x 10853 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results\n",
    "dfTrain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc28a89",
   "metadata": {},
   "source": [
    "### Implement KNN Recommendation Algorithm\n",
    "\n",
    "Here I will implement a class to carry out collaborative filtering based upon k-nearest neighbours. The model is meant to identify the K most similiar users, for any given input userId we specifiy. This implementation will make use of maximising the cosine similarity, as this distance measure typically performs well for high dimensional data and has a standard output ranging between (-1,+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28f29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    \"\"\"\n",
    "    Class for KNN recommender system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, K : int = 3) -> None:\n",
    "        \"\"\"\n",
    "        Initializer function for the class.\n",
    "        Inputs:\n",
    "            K      -> integer specifying number of neighbours to consider\n",
    "        \"\"\"\n",
    "        # store/initialise input parameters\n",
    "        self.K       = K\n",
    "        self.dfXtrain = pd.DataFrame()\n",
    "        \n",
    "    def __del__(self) -> None:\n",
    "        \"\"\"\n",
    "        Destructor function. \n",
    "        \"\"\"\n",
    "        del self.K\n",
    "        del self.dfXtrain\n",
    "    \n",
    "    def __cosine(self, sUser : pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Private function to compute the cosine similarity between point sUser and the training data dfXtrain\n",
    "        Inputs:\n",
    "            sUser -> pandas series data point of predictors to consider\n",
    "        Outputs:\n",
    "            dfCosine_s -> pandas dataframe of the computed similarities\n",
    "        \"\"\"\n",
    "        # compute cosine similarity\n",
    "        cosine_s = (np.dot(sUser,self.dfXtrain)/(np.linalg.norm(sUser)*np.linalg.norm(self.dfXtrain,axis=0)))\n",
    "        # attach column headers\n",
    "        dfCosine_s = pd.DataFrame(cosine_s.reshape((1,-1)),columns=self.dfXtrain.columns,index=['row'])\n",
    "        # return\n",
    "        return dfCosine_s\n",
    "        \n",
    "    def fit(self, dfX : pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Public training function for the class. \n",
    "        It is assummed input dfX has been normalised, and columns represent distinct users.\n",
    "        Inputs:\n",
    "            dfX -> numpy array containing the predictor features\n",
    "        \"\"\"\n",
    "        # store training data\n",
    "        self.dfXtrain = dfX.copy()\n",
    "        \n",
    "    def predict(self, x_users : list) -> Dict:\n",
    "        \"\"\"\n",
    "        Public prediction function for the class. \n",
    "        Inputs:\n",
    "            x_users -> list of userIds to make predictions for\n",
    "        Outputs:\n",
    "            dcOut -> dictionary containing the predicted K most similar users for each input userId\n",
    "        \"\"\"\n",
    "        # ensure we have already trained the instance\n",
    "        if self.dfXtrain.empty:\n",
    "            raise Exception('Model is not trained. Call fit before calling predict.')\n",
    "        # check for missing users (input userId's that aren't in the training data)\n",
    "        missing_users = list(set(x_users) - set(self.dfXtrain.columns.values))\n",
    "        if missing_users:\n",
    "            print('The following input users are not present in the training data: {}\\n\\n'.format(missing_users))\n",
    "        # work out valid users we can make recommendations for\n",
    "        valid_users = list(set(x_users) - set(missing_users))\n",
    "        print('Total number of input users to be analysed: {}'.format(len(valid_users)))\n",
    "        # loop through each input user to identify the K most similar users in the training data\n",
    "        dcRec = {}\n",
    "        for user in valid_users:\n",
    "            # extract user \n",
    "            sUser = self.dfXtrain[user].copy()\n",
    "            # compute cosine similarity\n",
    "            dfCosine_s = self.__cosine(sUser)\n",
    "            # obtain the K nearest neighbours\n",
    "            dfCosine_s = dfCosine_s.sort_values(by='row',ascending=False,axis=1)\n",
    "            y_pred = dfCosine_s.iloc[:,1:(self.K+1)].columns.tolist()\n",
    "            # store the predictions\n",
    "            dcRec[user] = y_pred\n",
    "        # return results\n",
    "        return dcRec\n",
    "    \n",
    "    def get_params(self, deep : bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Public function to return model parameters\n",
    "        Inputs:\n",
    "            deep -> boolean input parameter\n",
    "        Outputs:\n",
    "            Dict -> dictionary of stored class input parameters\n",
    "        \"\"\"\n",
    "        return {'K':self.K}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8deb2",
   "metadata": {},
   "source": [
    "Let's fit an instance of this class on the training data, and then obtain the most similar users for each userId in our test set, where possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6866927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KNN instance with K = 10\n",
    "recommender = KNN(K=10)\n",
    "# fit the recommender instance\n",
    "recommender.fit(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d8055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following input users are not present in the training data: [6145, 30727, 98316, 66075, 153118, 111139, 51763, 76342, 132152, 158265, 28226, 34884, 134728, 152136, 109643, 138318, 102479, 99408, 73302, 108636, 56925, 19049, 69227, 73843, 20600, 36472, 127610, 14457, 53372, 60540, 82563, 145540, 104069, 132239, 63124, 108181, 8343, 111259, 136875, 160430, 109743, 46264, 14521, 9402, 58566, 131783, 47815, 17097, 95946, 84683, 32456, 110287, 58580, 106202, 66269, 40672, 66786, 7907, 68326, 83696, 2806, 25847, 113400, 28927, 30469, 79626, 67862, 39704, 66334, 126238, 15138, 10033, 129850, 121663, 73035, 137038, 44888, 126306, 152932, 20837, 39275, 127854, 123248, 34675, 127859, 136566, 55670, 58251, 71568, 31122, 27540, 54679, 114588, 105373, 37793, 141218, 94626, 100773, 1447, 18865, 118708, 56759, 144319, 137667, 107976, 24538, 11228, 85469, 7644, 141793, 65506, 161269, 81403, 123903]\n",
      "\n",
      "\n",
      "Total number of input users to be analysed: 2581\n"
     ]
    }
   ],
   "source": [
    "# obtain predictions\n",
    "dcRec = recommender.predict(dfTest.userId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590ce01",
   "metadata": {},
   "source": [
    "There are a number of users we can't make recommendations for, since no records for them are present in the training data. This likely results from these users having a minimal number of ratings in the MovieLens dataset, which were all picked up during our sampling of the test set. \n",
    "\n",
    "Despite this, we still have adequate data for 2581 users. Let's now make recommendations, and measure how effective our recommender is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9afbd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def precision_at_k(df: pd.DataFrame, k: int=3, y_test: str='y_actual', y_pred: str='y_recommended') -> float:\n",
    "    \"\"\"\n",
    "    Function to compute precision@k for an input boolean dataframe\n",
    "    \n",
    "    Inputs:\n",
    "        df     -> pandas dataframe containing boolean columns y_test & y_pred\n",
    "        k      -> integer number of items to consider\n",
    "        y_test -> string name of column containing actual user input\n",
    "        y-pred -> string name of column containing recommendation output\n",
    "        \n",
    "    Output:\n",
    "        Floating-point number of precision value for k items\n",
    "    \"\"\"\n",
    "    # check we have a valid entry for k\n",
    "    if k <= 0:\n",
    "        raise ValueError('Value of k should be greater than 1, read in as: {}'.format(k))\n",
    "    # check y_test & y_pred columns are in df\n",
    "    if y_test not in df.columns:\n",
    "        raise ValueError('Input dataframe does not have a column named: {}'.format(y_test))\n",
    "    if y_pred not in df.columns:\n",
    "        raise ValueError('Input dataframe does not have a column named: {}'.format(y_pred))\n",
    "        \n",
    "    # extract the k rows\n",
    "    dfK = df.head(k)\n",
    "    # compute number of recommended items @k\n",
    "    denominator = dfK[y_pred].sum()\n",
    "    # compute number of recommended items that are relevant @k\n",
    "    numerator = dfK[dfK[y_pred] & dfK[y_test]].shape[0]\n",
    "    # return result\n",
    "    if denominator > 0:\n",
    "        return numerator/denominator\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def recall_at_k(df: pd.DataFrame, k: int=3, y_test: str='y_actual', y_pred: str='y_recommended') -> float:\n",
    "    \"\"\"\n",
    "    Function to compute recall@k for an input boolean dataframe\n",
    "    \n",
    "    Inputs:\n",
    "        df     -> pandas dataframe containing boolean columns y_test & y_pred\n",
    "        k      -> integer number of items to consider\n",
    "        y_test -> string name of column containing actual user input\n",
    "        y-pred -> string name of column containing recommendation output\n",
    "        \n",
    "    Output:\n",
    "        Floating-point number of recall value for k items\n",
    "    \"\"\"\n",
    "    # check we have a valid entry for k\n",
    "    if k <= 0:\n",
    "        raise ValueError('Value of k should be greater than 1, read in as: {}'.format(k))\n",
    "    # check y_test & y_pred columns are in df\n",
    "    if y_test not in df.columns:\n",
    "        raise ValueError('Input dataframe does not have a column named: {}'.format(y_test))\n",
    "    if y_pred not in df.columns:\n",
    "        raise ValueError('Input dataframe does not have a column named: {}'.format(y_pred))\n",
    "        \n",
    "    # extract the k rows\n",
    "    dfK = df.head(k)\n",
    "    # compute number of all relevant items\n",
    "    denominator = df[y_test].sum()\n",
    "    # compute number of recommended items that are relevant @k\n",
    "    numerator = dfK[dfK[y_pred] & dfK[y_test]].shape[0]\n",
    "    # return result\n",
    "    if denominator > 0:\n",
    "        return numerator/denominator\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1891bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select out the required columns from the raw training dataframe\n",
    "dfTrainRaw = dfTrainRaw[['userId','movieId','rating']].drop_duplicates()\n",
    "\n",
    "# set threshold for relevant/non-relevant movies, k for metrics, and initialise metrics lists\n",
    "threshold = 3.0\n",
    "k = 5\n",
    "pre_at_k = []\n",
    "rec_at_k = []\n",
    "\n",
    "# loop through our test set results and evaluate recommendations\n",
    "for userId in dcRec.keys():\n",
    "    \n",
    "    # get movies already watched \n",
    "    movies_already_watched = dfTrainRaw[dfTrainRaw.userId == userId].movieId.unique()\n",
    "    \n",
    "    # collect all movies watched by the K similar users, and not already watched by userId\n",
    "    dfSim = dfTrainRaw[ (~dfTrainRaw.movieId.isin(movies_already_watched)) & \n",
    "                        (dfTrainRaw.userId.isin(dcRec[userId])) ].copy()\n",
    "    \n",
    "    # group on movieId, and then compute the mean rating\n",
    "    dfRatings = dfSim.groupby(by='movieId')['rating'].mean().reset_index()\n",
    "    dfRatings.columns = ['movieId','predicted_rating']\n",
    "    \n",
    "    # select out entries in the test set that correspond to our user\n",
    "    dfTestUser = dfTest.loc[dfTest.userId == userId,['movieId','rating']].copy()\n",
    "    dfTestUser.columns = ['movieId','actual_rating']\n",
    "    \n",
    "    # merge the user entries with the recommended movies\n",
    "    dfResults = pd.merge(dfRatings,dfTestUser,on=['movieId'],how='inner').drop(['movieId'],axis=1)\n",
    "    \n",
    "    # convert results into boolean dataframe\n",
    "    dfResults = dfResults > threshold\n",
    "    \n",
    "    # compute precision@k & recall@k\n",
    "    patk = precision_at_k(dfResults,k=k,y_test='actual_rating',y_pred='predicted_rating')\n",
    "    ratk = recall_at_k(dfResults,k=k,y_test='actual_rating',y_pred='predicted_rating')\n",
    "    pre_at_k.append(patk)\n",
    "    rec_at_k.append(ratk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01e7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values\n",
    "pre_at_k = np.array([i for i in pre_at_k if i is not None])\n",
    "rec_at_k = np.array([i for i in rec_at_k if i is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5eaa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k mean: 0.8240777338603426, median: 1.0, and standard deviation: 0.35613771881889705\n",
      "Recall@k mean: 0.8575273587695948, median: 1.0, and standard deviation: 0.31836093173585117\n"
     ]
    }
   ],
   "source": [
    "# compute statistics on our results\n",
    "print('Precision@k mean: {0}, median: {1}, and standard deviation: {2}'.format(np.mean(pre_at_k),\n",
    "                                                                               np.median(pre_at_k),\n",
    "                                                                               np.std(pre_at_k)))\n",
    "print('Recall@k mean: {0}, median: {1}, and standard deviation: {2}'.format(np.mean(rec_at_k),\n",
    "                                                                            np.median(rec_at_k),\n",
    "                                                                            np.std(rec_at_k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3190fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.hist(pre_at_k,alpha=0.5,edgecolor='black',label='precision@k',color='red')\n",
    "plt.hist(rec_at_k,alpha=0.5,edgecolor='black',label='recall@k',color='yellow')\n",
    "plt.title('Distribution of Precision@k and Recall@k for k=5')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279504fc",
   "metadata": {},
   "source": [
    "These results are quite encouraging: the mean and median results show that the top K=5 movie recommendations capture the clear majority of relevant movies in the test set. This conclusion is also supported by the histogram plot illustrating our results for individual users.\n",
    "\n",
    "Note that there are ways we can try to improve the model. One point that could be tried is to enhance how the ratings dataframe is built from the output of the recommender. In this notebook, I computed the mean rating over the K most similar users. This does not take into account the relative degree of similarity these users have to the intended target user. You could try to extract the cosine similarity scores from the KNN instance, and use this to compute a weighted mean rating instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
