{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8660be2a-1dcf-4abd-893f-858270f341c3",
   "metadata": {},
   "source": [
    "# PageRank\n",
    "\n",
    "In this notebook, we'll cover an implementation of the basic PageRank algorithm. In the example here, we will be working exclusively with a directed graphs.\n",
    "\n",
    "PageRank was developed originally at Google by Larry Page and Sergey Brin. This algorithm is famous for being the original basis for the Google Search Engine. See: https://www.cis.upenn.edu/~mkearns/teaching/NetworkedLife/pagerank.pdf?ref=ruky.me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d949538f-b55a-44d5-adab-165fdea6855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknetwork as skn\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2330ddf-f638-414b-a86d-f626f3164300",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(\"A\", \"B\"),(\"B\", \"D\"),(\"D\", \"A\"),(\"D\",\"C\"),(\"A\", \"C\"),(\"C\", \"A\"),(\"D\",\"E\"),(\"F\",\"D\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7363220e-5710-4a65-9627-e835b67a94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = skn.data.from_edge_list(edges, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2f1cd6-6be9-4691-bf55-bebce28bbc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"452.0\" height=\"352\">\n",
       "<defs><marker id=\"arrow-gray\" markerWidth=\"10\" markerHeight=\"10\" refX=\"9\" refY=\"3\" orient=\"auto\">\n",
       "<path d=\"M0,0 L0,6 L9,3 z\" fill=\"gray\"/></marker></defs>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 97 279 248 309\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 97 279 30 208\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 254 310 246 205\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 26 203 93 274\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 246 199 103 276\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 246 199 32 203\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 246 199 294 38\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<path stroke-width=\"1\" stroke=\"gray\" d=\"M 426 332 251 203\" marker-end=\"url(#arrow-gray)\"/>\n",
       "<circle cx=\"97\" cy=\"279\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"254\" cy=\"310\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"26\" cy=\"203\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"246\" cy=\"199\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"296\" cy=\"32\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<circle cx=\"426\" cy=\"332\" r=\"7.0\" style=\"fill:gray;stroke:black;stroke-width:1.0\"/>\n",
       "<text text-anchor=\"middle\" x=\"97\" y=\"269\" font-size=\"12\">A</text><text text-anchor=\"middle\" x=\"254\" y=\"300\" font-size=\"12\">B</text><text text-anchor=\"middle\" x=\"26\" y=\"193\" font-size=\"12\">C</text><text text-anchor=\"middle\" x=\"246\" y=\"189\" font-size=\"12\">D</text><text text-anchor=\"middle\" x=\"296\" y=\"22\" font-size=\"12\">E</text><text text-anchor=\"middle\" x=\"426\" y=\"322\" font-size=\"12\">F</text></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = skn.visualization.graphs.visualize_graph(adjacency=graph.adjacency, names=graph.names, name_position='above')\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c4c4d-81d6-4cfe-90bb-813a84bd4ee3",
   "metadata": {},
   "source": [
    "## First Attempt: Simplified Approach\n",
    "\n",
    "To gain some intuition, let's first work through a basic version of the algorithm. We will create an iterative procedure, that will function as follows:\n",
    "* initialize all nodes in the graph to have the same rank value $= 1/(\\text{number of nodes in the graph})$\n",
    "* on each iteration, transfer the rank value from the source node to destination node in proportion to the number of out-edges from the source node\n",
    "\n",
    "To express how rank value $P_r$ is transferred mathematically:\n",
    "\n",
    "$P_r(p_i) = \\sum_{\\text{edges}_{ji}} \\frac{P_r(p_j)}{O_{j}}$\n",
    "\n",
    "where $p$ represents the pages/nodes in our graph, $i$ indexes over the destination nodes, $j$ indexes over the source nodes, and $O$ is a count of all the outlinks from the $j^{th}$ source node. We compute the above ratio and sum over all existing edges that run from $j$ to $i$.\n",
    "\n",
    "### Problems with the Simplified Approach\n",
    "\n",
    "Nodes E and F represent problems for the simplified algorithm presented above. Node E is a sink, where it only has an input edge directed towards it. As a consequence, rank value will tend to to be lost at this node over successive iterations in the algorithm. For node F, which is a source node, on the first iteration the assigned rank value for F will be granted to node D, and F will be left with a value of 0.\n",
    "\n",
    "This doesn't seem to be sensible treatment for source or sink nodes. Let's make a somewhat more sophisticated algorithm, to handle nodes like E & F!\n",
    "\n",
    "## A More Sophisticated Approach: Introducing the Damping Factor\n",
    "\n",
    "We can make a more realistic model by introducing a *damping factor* $d$, that is the probability a user will follow a link on page $p_j$ to page $p_i$. Conversely, $1-d$ is termed the *fly-out probability*, which is the chance a user will select a new page at random (i.e. will not follow an edge in the graph). With the inclusion of $d$, it is now possible to move past node E after landing on it, and it is possible to arrive back at F after leaving it.\n",
    "\n",
    "Mathematically, we can include the damping factor in the following way:\n",
    "\n",
    "$P_r(p_i) = d\\sum_{\\text{edges}_{ji}} \\frac{P_r(p_j)}{O_{j}} + \\frac{1-d}{N_p}$\n",
    "\n",
    "where $N_p$ is the total number of pages/nodes in the graph. \n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "We can now write out the algorithm we will follow here for each iteration $t=0,1,2,...$:\n",
    "\n",
    "1. Initialize the rank values for all pages $P_r(p_i; t)$ in the graph at $t=0$ with: $P_r(p_i; 0)=\\frac{1}{N_p}$\n",
    "2. For $t=1,2,3,...$ update the rank values with $P_r(p_i;t+1) = d\\sum_{\\text{edges}_{ji}} \\frac{P_r(p_j;t)}{O_{j}} + \\frac{1-d}{N_p}$\n",
    "\n",
    "Let's write things more compactly, by writing a matrix equation using the following objects:\n",
    "\n",
    "${\\bf P_r(t)} = \\begin{bmatrix} P_r(p_0;t) \\\\ P_r(p_1;t) \\\\ \\vdots \\\\ P_r(p_{N_p};t) \\end{bmatrix}$\n",
    "\n",
    "${\\bf D} = \\begin{bmatrix} 1/D_{0,0} && 0 && \\cdots && 0 \\\\ \n",
    "                           0 && 1/D_{1,1} &&        && \\vdots \\\\\n",
    "                            \\vdots    &&           && \\ddots &&        \\\\\n",
    "                           0 && \\cdots  &&        && 1/D_{N_p,N_p} \\end{bmatrix}$\n",
    "\n",
    "${\\bf O} = \\begin{bmatrix} O_{0,0} && O_{0,1} && \\cdots && O_{0,N_p} \\\\ \n",
    "                           O_{1,0} && O_{1,1} &&        && \\vdots \\\\\n",
    "                           \\vdots    &&           && \\ddots &&        \\\\\n",
    "                           O_{N_p,0} && \\cdots  &&        && O_{N_p,N_p} \\end{bmatrix}$\n",
    "\n",
    "${\\bf \\hat{O}} = {\\bf OD}$\n",
    "\n",
    "Here we have: \n",
    "* ${\\bf P_r(t)}$ is a column vector containing all the page ranks at step $t$\n",
    "* ${\\bf D}$ is a square diagonal matrix, where each element along the diagonal is either the inverse of the out-degree of node $i$, or $0.0$ if there are no outgoing edges\n",
    "* ${\\bf O}$ is the square adacency matrix for the graph\n",
    "* ${\\bf \\hat{O}}$ is a modified form of the adacency matrix, where each element $\\hat{O}_{i,j}$ is the ratio of edges from $j \\rightarrow i$ divided by the total out-degree of node $j$\n",
    "* each column in ${\\bf \\hat{O}}$ is normalized to sum to 1.0\n",
    "\n",
    "Now we can rewrite the PageRank update at $t+1$ as:\n",
    "\n",
    "${\\bf P_r(t+1)} = d{\\bf \\hat{O}P_r(t)} + \\frac{1-d}{N_p}{\\bf 1}$\n",
    "\n",
    "where the column vector ${\\bf 1}$ consists of $N_p$ elements all set to 1.0.\n",
    "\n",
    "We can continue updating until convergence is reached as set by $\\epsilon$:\n",
    "\n",
    "$|{\\bf P_r(t+1)} - {\\bf P_r(t)}| < \\epsilon$\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Let's now proceed to implement the algorithm covered above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e82f46b-9f9f-4d42-aaa6-3cca34a87736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "\n",
    "    def __init__(self, edges: List[Tuple]) -> None:\n",
    "        # initialize objects\n",
    "        nodes = set()\n",
    "        indegrees = {}\n",
    "        outdegrees = {}\n",
    "        # determine the unique set of nodes in the graph, and count number of outbound edges per source node\n",
    "        for edge in edges:\n",
    "            nodes.update(list(edge))\n",
    "            src, dst = edge\n",
    "            try:\n",
    "                outdegrees[src] += 1\n",
    "            except:\n",
    "                outdegrees[src] = 1\n",
    "            try:\n",
    "                indegrees[dst] += 1\n",
    "            except:\n",
    "                indegrees[dst] = 1\n",
    "        nodes = list(nodes)\n",
    "        nodes.sort()\n",
    "        # store graph data\n",
    "        self.edges = edges\n",
    "        self.nodes = nodes\n",
    "        self.number_nodes = len(nodes)\n",
    "        self.number_edges = len(edges)\n",
    "        self.indegrees = indegrees\n",
    "        self.outdegrees = outdegrees\n",
    "\n",
    "    def _build_adjacency_matrix(self) -> np.array:\n",
    "        # work out adjacency matrix\n",
    "        O = np.zeros((self.number_nodes,self.number_nodes))\n",
    "        for edge in self.edges:\n",
    "            src, dst = edge\n",
    "            O[self.nodes.index(dst),self.nodes.index(src)] += 1\n",
    "        return O\n",
    "\n",
    "    def _build_outdegree_matrix(self) -> np.array:\n",
    "        D = np.zeros((self.number_nodes,self.number_nodes))\n",
    "        for node in self.nodes:\n",
    "            try:\n",
    "                D[self.nodes.index(node),self.nodes.index(node)] = 1/self.outdegrees[node]\n",
    "            except:\n",
    "                D[self.nodes.index(node),self.nodes.index(node)] = 0\n",
    "        return D\n",
    "    \n",
    "    def get_modified_adjacency_matrix(self) -> np.array:\n",
    "        return np.matmul(self._build_adjacency_matrix(),self._build_outdegree_matrix())\n",
    "    \n",
    "    def get_edges(self) -> List[Tuple]:\n",
    "        return self.edges\n",
    "\n",
    "    def get_nodes(self) -> List:\n",
    "        return self.nodes\n",
    "\n",
    "    def get_number_edges(self) -> int:\n",
    "        return self.number_edges\n",
    "\n",
    "    def get_number_nodes(self) -> int:\n",
    "        return self.number_nodes\n",
    "\n",
    "    def get_indegrees(self) -> dict:\n",
    "        return self.indegrees\n",
    "    \n",
    "    def get_outdegrees(self) -> dict:\n",
    "        return self.outdegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e352066f-7f2a-46af-ad83-51a02a14934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank(object):\n",
    "\n",
    "    def __init__(self, damping_factor: float=0.85, epsilon: float=1e-8) -> None:\n",
    "        self.damping_factor = damping_factor\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def _initalize_pagerank(self, graph: Graph) -> np.array:\n",
    "        return (1/graph.get_number_nodes())*np.ones((graph.get_number_nodes(),1))\n",
    "        \n",
    "    def _identity_vector(self, graph: Graph) -> np.array:\n",
    "        return np.ones((graph.get_number_nodes(),1))\n",
    "\n",
    "    def _step(self, P1: np.array, I: np.array, graph: Graph) -> np.array:\n",
    "        P2 = (\n",
    "            self.damping_factor*np.matmul(graph.get_modified_adjacency_matrix(),P1) \n",
    "            + (1 - self.damping_factor)*I/graph.get_number_nodes()\n",
    "        )\n",
    "        return(P2/np.sum(P2))\n",
    "    \n",
    "    def evaluate(self, graph: Graph) -> dict:\n",
    "        # obtain nodes from graph\n",
    "        nodes = graph.get_nodes()\n",
    "        # setup initial pagerank steps\n",
    "        P1 = self._initalize_pagerank(graph)\n",
    "        I  = self._identity_vector(graph)\n",
    "        P2 = self._step(P1, I, graph)\n",
    "        # step through the algorithm, updating our pageranks \n",
    "        while(np.linalg.norm(P1 - P2) >= self.epsilon):\n",
    "            P1 = P2\n",
    "            P2 = self._step(P1, I, graph)\n",
    "        # package results and return\n",
    "        pageranks = {}\n",
    "        for node, rank in zip(nodes,P2.flatten()):\n",
    "            pageranks[node] = rank\n",
    "        return pageranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa254b75-4c65-479b-b316-b65d23759045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph object\n",
    "graph = Graph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6553e38-3078-4889-a216-acbff90d60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pagerank object\n",
    "pr = PageRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64b66b7-5b5f-4d19-b404-0aa8a9af730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pageranks\n",
    "ranks = pr.evaluate(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b52a42e-a7e2-40ca-9fdb-69ca492697f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.29526336887933935,\n",
       " 'B': 0.16277503210453523,\n",
       " 'C': 0.22454693557427846,\n",
       " 'D': 0.20155998078146667,\n",
       " 'E': 0.08881329306506174,\n",
       " 'F': 0.027041389595318478}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63306055-acbf-4584-9e7c-c443452d153b",
   "metadata": {},
   "source": [
    "These results seem sensible: the most interconnected nodes A, C, & D have the largest rank values. At the same time F, with no inbound links, has by far the lowest rank. \n",
    "\n",
    "## Verify Results\n",
    "\n",
    "Let's now double check our results, by comparing with the built-in PageRank from scikit-network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3195ce4-2bbb-4791-ae1c-b129df1fcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sknetwork.ranking import PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dbb9b7-8f80-45a3-9090-cc108c995a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = skn.data.from_edge_list(edges, directed=True)\n",
    "#adjacency = graph.adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4376c-bcb5-4f89-a29f-ec4e77f0e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pagerank = PageRank()\n",
    "#scores = pagerank.fit_predict(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500637e6-e069-4473-81ef-855d51d3ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89b336-9981-47c1-8528-7d212d300ba2",
   "metadata": {},
   "source": [
    "For the most part, the rankings here look very similar to those obtained with our custom implementation. Nodes A, C, and D are among the highest ranked in the graph, which makes sense as they have a large degree. The biggest difference between the two sets of results is the page rank for node E, where this value is given more weight through the scikit-network model. \n",
    "\n",
    "As mentioned previously, Node E is a sink, or *dangling node*. The classic PageRank algorithm, presented here, has a hard time dealing with dangling nodes correctly. This fact is highlighted by the discrepancy between the two sets of values. Further alterations to the PageRank algorithm are required to handle nodes like E. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921cab4-a561-4068-8ef0-bb9e351e93cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
